\chapter{Algorithmic Elaboration and History}

\begin{abstract}
This chapter explores the development of mathematical concepts through algorithmic elaboration, arguing that mathematical history reflects a dialectical pattern where apparent completion generates new possibilities. The analysis connects the reconceptualization of numerals as pronouns with critical arithmetic development, demonstrating how Robert Brandom's concept of algorithmic elaboration models this evolution. Two case studies anchor the analysis: Euclid's proof of the infinity of primes reconstructed through incompatibility semantics, and the emergence of arithmetic operations from embodied metaphors. The investigation reveals the limitations of simple algorithmic elaboration, necessitating ``pragmatic expressive bootstrapping'' where conceptual systems explicate their implicit normative structures. Rather than treating intellectual history as a static literature to be surveyed, I advocate understanding it as dynamic conceptual development mirroring the algorithmic elaboration within mathematical practice itself.
\end{abstract}

\section{The Problem of Cataloguing Sand}

Algorithms are traditionally conceived as step-by-step procedures for solving problems. An algorithm takes input, processes it through defined steps, and produces output. What this definition misses is the underlying inferential structure: algorithms are chains of inferences, as discussed in section \ref{def:algorithms}. These inferential chains can become smooth through practice, like a yogi flowing between poses. Of particular interest are chains of material inference (recall \ref{def:material-inference}) involving substitution.

When I proposed this book, I intended to explore literature reviews as a concept. The perceived lack of importance of the dissertation literature review is evident in the paucity of research devoted to understanding it \parencite[4]{boote2005}. I thought articulating the process would be a gift to future scholars. Yet as I wrote, the earth shifted beneath my feet. The popularization of Large Language Models transformed summarizing and synthesizing into seemingly passive activities.

More fundamentally, I encountered a paradox. Each attempt to gain purchase on ``The Literature'' as a totality revealed new gaps. One article would fill a gap, revealing another, then another. I had not yet synthesized the groundless ground; I was trying to climb onto the shoulders of giants made of sand. The Bridge chapter articulates this process: reifying a totality in a name inevitably leads to expressions that cannot have been in the reified totality but must have been in the original totality. This process haunts any attempt to conceptualize ``The Literature.''

\section{Algorithmic Elaboration as Living History}

Instead of treating literature review as cataloguing static objects, I propose understanding intellectual history through algorithmic elaboration. Brandom introduces this concept through long division \parencite[37]{Brandom2008}, showing how the division algorithm elaborates from multiplication and subtraction practices. Figure \ref{fig:brandom_figure_2_3} reproduces his automaton-implemented elaboration.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{/Users/tio/Documents/GitHub/September_UMEDCA/images/brandom_2_3.pdf}
    \caption{\textit{Note.} Automaton-implemented, algorithmically elaborated, pragmatically mediated semantic relation reproduced from \parencite[37]{Brandom2008}.}
    \label{fig:brandom_figure_2_3}
\end{figure}

My initial skepticism about this example was intense. The rich semantic structure of division seems hardly captured by the long-division algorithm. The claim felt incomplete without tracking how counting elaborates into addition, addition into multiplication and subtraction. Consider the algebraic structures of basic arithmetic operations shown in Table \ref{tab:arithmetic-operations}.

\begin{table}[h]
\centering
\caption{\textbf{\textit{Algebraic Structure of Basic Arithmetic Operations}}}
\label{tab:arithmetic-operations}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Operation} & \textbf{Algebraic Structure} \\
\midrule
Addition & $\fbox{\text{Known Part}}+ \fbox{\text{Known Part}}= \fbox{\text{Unknown Whole}}$ \\[0.5ex]
Subtraction & $\fbox{\text{Unknown Part}}+ \fbox{\text{Known Part}}= \fbox{\text{Known Whole}}$ \\[0.5ex]
Equal-Groups Multiplication & $\fbox{\text{Known Items per Group}}\times \fbox{\text{Known Number of Groups}}= \fbox{\text{Unknown Total}}$ \\[0.5ex]
Sharing Division & $\fbox{\text{Unknown Items per Group}}\times \fbox{\text{Known Number of Groups}}= \fbox{\text{Known Total}}$ \\[0.5ex]
Measurement Division & $\fbox{\text{Known Items per Group}}\times \fbox{\text{Unknown Number of Groups}}= \fbox{\text{Known Total}}$ \\
\bottomrule
\end{tabular}
\end{table}

These structures suggest deeper dialectical shifts at work. Is subtraction simply elaborated from addition by ``reversing the wiring,'' or does conceptual understanding require dialectical thinking? The mechanical attributes of automata modeling arithmetic vary significantly. Kindergarten emphasizes three-step procedures as prerequisites. Matching nested parentheses for von Neumann ordinals requires push-down stack automata with primitive memory, not mere finite-state machines.

\section{Euclid's Proof: Incompleteness as Incoherence}

To demonstrate algorithmic elaboration concretely, I reconstruct Euclid's proof using Brandom's incompatibility semantics \parencite{Brandom2008}. First, key concepts:

An \textit{incoherence frame} is a pair $\langle L, Inc \rangle$ where $Inc$ specifies which sentences in language $L$ are incoherent. Think of this as sentences a qualitative researcher seeks to understand, or troubling interactions people reflect upon to make sense of them. Incoherence can be existentially terrifying. When recognized as believing both $x$ and $\neg x$, I might be understood as becoming, or as duplicitous. Context matters profoundly.

An \textit{incompatibility relation} $I$ defines two sets $X$ and $Y$ as incompatible if their union is incoherent: $A \in I(B) \iff A \cup B \in Inc$.

Euclid's proof (Book 9, Proposition 20 of \textit{The Elements} \parencite{euclid_euclids_2007}) claims any finite list of primes is incomplete. The common misrepresentation suggests Euclid provides an algorithm for finding primes. This is false. He only claims that multiplying all known primes and adding one yields a number not divisible by any known prime. The number $2\times 3 \times 5 \times 7\times 11\times 13+1=30031=59\times 509$ is composite, not prime.

Euclid's actual argument: Take primes $A$, $B$, $C$. Form $DE$ as their product. Add one unit to get $EF = DE + 1$. Either $EF$ is prime (thus a new prime beyond the list) or composite with prime factor $G$ that cannot equal $A$, $B$, or $C$ (since if $G$ divided both $DE$ and $EF$, it would divide their difference, which is $1$).

\begin{figure}[h]
	\includegraphics{/Users/tio/Documents/GitHub/September_UMEDCA/images/Cuisenaire_Rods.pdf}
	\caption{\textit{Note.} Cuisenaire rods interpreted as numerals 1-10, building composite 6 from primes ($2\times 3$), and algorithm for Euclid's proof.}
	\label{fig:rods}
\end{figure}

Through incompatibility semantics, the key insight becomes: $\{\text{The list of primes } \{A, B, C\} \text{ is complete}\} \in Inc$.

This statement belongs to the incoherence frame because it generates internal contradiction. The claim to completeness defeats itself through the construction $N = A \times B \times C + 1$.

\section{The Reflective Turn: Admitting Incoherence}

Here the chapter pivots. The reconstruction above reveals something profound: the notion of an incoherence frame allows errors, misrecognitions, mistakes, and misconceptions to be \textbf{admitted} into the system without damaging its coherence (label: \ref{def:admitting_incoherence}). When an algorithm produces a paradoxical result, that paradox becomes an element of an incoherence frame rather than a problem to solve.

This transforms our understanding. Mathematical learning might proceed not through avoiding error but through sophisticated recognition and integration of contradictory commitments. Barriers become resources for development. In formal mathematics, contradictory commitments are dropped as falsities. In mathematics education, tensions of misrecognition are sublated into new understanding; they do not simply disappear.

I formalized this insight in Prolog, creating \texttt{more\_machine\_learner.pl}. The engine does not take axioms and prove theorems. Instead, it takes premises and proves incoherence. This subtle difference captures Euclid's proof structure: demonstrating that assuming completeness leads to incoherence. The formalism helps ensure the system I outline is itself coherent, though readers should take it with appropriate skepticism. I had extensive AI assistance cobbling together code to ``prove'' theorems. Yet from the Hermeneutic Calculator to the Prolog supplements, readers can see claims in action.

My ambition is not a finished system but a starting point for others to build upon, as I have built on others' work.

\section{From Embodied Metaphors to Arithmetic}

The dialectical insight about admitting incoherence prepares us to understand how arithmetic emerges from embodied experience. Following Lakoff and Núñez \parencite{Lakoff2000}, I synthesize embodied metaphors with incompatibility semantics.

\subsection*{Bounded Regions and Categories}

Proprioceptive feelings define boundaries: an interior (inside the body) and exterior (outside). The vocabulary transitions algorithmically:

\begin{enumerate}
    \item If you are in a bounded region, you are not out of that bounded region.
    \item If you are out of a bounded region, you are not in that bounded region.
    \item If you are deep in a bounded region, you are far from being out.
    \item If you are on the edge of a bounded region, you are close to being in.
\end{enumerate}

Through substitution:
\begin{itemize}
    \item ``Categories'' for ``Bounded regions in space''
    \item ``Category members'' for ``Objects inside bounded regions''
    \item ``Subcategory of larger category'' for ``One bounded region inside another''
\end{itemize}

\subsection*{Material Inferences for Object Collections}

To establish arithmetic foundations, I explicate material inferences governing object collections, enabling vocabulary $V_{\text{object collection}}$:

\[
V_{\text{object collection}} = \{\text{bigger}, \text{smaller}, =, \text{added to}, \text{results in}, \text{adding}, \text{subtract}, \text{zero}, \text{one}\}
\]

Key inferences include:

\textbf{Linearity}: $\{ A \text{ and } B \text{ are object collections} \} \dagger$ (Highlander algorithm)
\begin{itemize}
    \item $\{ A \text{ bigger than } B \} \vDash_{I} \{ B \text{ smaller than } A \} \rightarrow \neg \{ A \text{ smaller than } B \}$
    \item $\{ B \text{ bigger than } A \} \vDash_{I} \{ A \text{ smaller than } B \} \rightarrow \neg \{ B \text{ smaller than } A \}$
    \item $\{ A = B \}$
\end{itemize}

\textbf{Limited Iteration of Subtraction}:
\begin{itemize}
    \item $\{ B \text{ smaller than } A \} \rightarrow \{ B \text{ subtracted from } A \text{ is an object collection} \}$
    \item $\{ B \text{ symmetrically intersubstitutable with } A \} \vDash_{I} \{ \text{No objects left when } A \text{ subtracted from } B \}$
\end{itemize}

These establish operations on object collections underpinning arithmetic, grounding them in deontic-normative structures rather than alethic assertions.

\section{Pragmatic Expressive Bootstrapping}

Simple algorithmic elaboration has limits. Dialectical moments require what Brandom calls \textit{pragmatic expressive bootstrapping} \parencite{Brandom2008}: new, more expressively powerful vocabularies emerge from implicit practices already mastered. The system pulls itself up by its bootstraps, making explicit what was latent in its doing.

This mirrors diagonalization from the Bridge chapter. A system constructs new elements demonstrably part of its potential but outside initial enumeration. Similarly, existing practices contain implicit resources to make explicit vocabularies transcending the language describing those practices.

Brandom formalizes this through Meaning-Use Analysis. Bootstrapping occurs when vocabulary $V'$ is VP-sufficient to specify practices $P$ that are PV-sufficient to deploy more powerful vocabulary $V$. The ``bootstrapping'' happens when specifying vocabulary ($V'$) is weaker than deployed vocabulary ($V$).

I implemented this computationally in \texttt{more\_machine\_learner.pl}. The system begins with norms for arithmetic over natural numbers where subtraction is limited: $3 - 5$ is nonsensical. When presented with observation \texttt{minus(3, 5, -2)}, it enters normative critique:

\begin{verbatim}
Observation is INCOHERENT with current norms. Entering critique phase...
Identified Incompatibility: incompatibility(limited_subtraction, domain(n))
Proposed Normative Shift: Change domain to z
Bootstrapping complete. Observation is now coherent.
\end{verbatim}

The system uses failure of its vocabulary (arithmetic over $\mathbb{N}$) to deploy new vocabulary (arithmetic over $\mathbb{Z}$). The paradox resolves not through dismissal but transformation.

\section{History as Self-Elaborating Process}

This chapter demonstrates that mathematical history, and conceptual history broadly, unfolds as rational algorithmic elaboration. From implicit practices of counting, measuring, and inferring, explicit formal systems emerge. Euclid's proof reconstructed through incompatibility semantics shows ancient insights as formal articulation of inferential commitments. Claims to completeness are self-defeating, opening doors to the infinite.

Yet knowledge's journey is not linear unfolding. Algorithmic elaboration's limitations necessitate dialectical ruptures requiring profound conceptual change. Pragmatic expressive bootstrapping provides the model: systems of practices generate new vocabularies making their implicit normative structures explicit. This is not magic but language unfolding itself.

Mathematical knowledge becomes not static truth collections but dynamic, self-correcting, emancipatory process: constant becoming. By understanding rules implicitly followed, it becomes possible to make them explicit, critique them, transcend them, or identify with them.

The shift from static literature review to dynamic conceptual development reveals how mathematical understanding operates. Rather than cataloguing sand, I trace how concepts elaborate themselves through material inference chains, admitting incoherence as resource rather than obstacle. This prepares readers for critical arithmetic in subsequent chapters, where operations emerge from embodied practices through normatively regulated elaboration.

\printbibliography[heading=subbibliography]
